{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1C29XcV-ykBUe9MVmlwPBBbh4IGtA-p9y","timestamp":1720081914460}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lP6JLo1tGNBg"},"source":["# Artificial Neural Network"]},{"cell_type":"markdown","metadata":{"id":"gWZyYmS_UE_L"},"source":["### Importing the libraries"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf   #tensorflow is preinstalled library in google collab - it's used for deep learning neural networks implementation.\n","tf.__version__   #to check the installed version of tensorflow , 2.17.0 is latest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"mjzo7fGm6hgr","executionInfo":{"status":"ok","timestamp":1720101039169,"user_tz":-330,"elapsed":9663,"user":{"displayName":"Mainks Sharma","userId":"04276220024164708980"}},"outputId":"ba6c427c-fe81-4937-926f-d1d3ae190246"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.15.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"1E0Q3aoKUCRX"},"source":["## Part 1 - Data Preprocessing\n","Data preprocessing : - It counts for 70% of work for a data scientists"]},{"cell_type":"markdown","metadata":{"id":"cKWAkFVGUU0Z"},"source":["### Importing the dataset"]},{"cell_type":"code","source":["dataset = pd.read_csv('Churn_Modelling.csv')\n","X = dataset.iloc[:,3:-1].values #our dataset(view),first 3 columns = rowid,CustomerID & Surname , have no correlation with dependent variable , So only required relative columns chosen.\n","y = dataset.iloc[:,-1].values #Dependent variable having only last column.\n","\n","print(X)\n","print('\\n')\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXIB837Y6ffW","executionInfo":{"status":"ok","timestamp":1720101039169,"user_tz":-330,"elapsed":5,"user":{"displayName":"Mainks Sharma","userId":"04276220024164708980"}},"outputId":"04ea6ce9-fa34-4ff5-b5f3-360e39ba66f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[619 'France' 'Female' ... 1 1 101348.88]\n"," [608 'Spain' 'Female' ... 0 1 112542.58]\n"," [502 'France' 'Female' ... 1 0 113931.57]\n"," ...\n"," [709 'France' 'Female' ... 0 1 42085.58]\n"," [772 'Germany' 'Male' ... 1 0 92888.52]\n"," [792 'France' 'Female' ... 1 0 38190.78]]\n","\n","\n","[1 0 1 ... 1 1 0]\n"]}]},{"cell_type":"markdown","metadata":{"id":"N6bQ0UgSU-NJ"},"source":["### Encoding categorical data"]},{"cell_type":"markdown","metadata":{"id":"le5MJreAbW52"},"source":["Label Encoding the \"Gender\" column"]},{"cell_type":"code","source":["#So in Matrix X of independent variables, we've two columns with categorical / alphabetical data - Gender(2nd column) and\n","#geography (1st column) , Gender can be labelencoded as it've two categorys only\n","#Geography have more than 2 categorical instances- onehotencoding is used (100 ,010,001)\n","\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","X[:,2] = le.fit_transform(X[:,2])\n","print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fTeIMo8x97rL","executionInfo":{"status":"ok","timestamp":1720101040005,"user_tz":-330,"elapsed":838,"user":{"displayName":"Mainks Sharma","userId":"04276220024164708980"}},"outputId":"d2a4fd54-0ed4-4d8c-8ec5-8c44baa7ef98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[619 'France' 0 ... 1 1 101348.88]\n"," [608 'Spain' 0 ... 0 1 112542.58]\n"," [502 'France' 0 ... 1 0 113931.57]\n"," ...\n"," [709 'France' 0 ... 0 1 42085.58]\n"," [772 'Germany' 1 ... 1 0 92888.52]\n"," [792 'France' 0 ... 1 0 38190.78]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"CUxGZezpbMcb"},"source":["One Hot Encoding the \"Geography\" column"]},{"cell_type":"code","source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder                  #column to onehotencode\n","ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [1] )], remainder = 'passthrough')\n","X = np.array(ct.fit_transform(X))\n","print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Gibhn60-qzg","executionInfo":{"status":"ok","timestamp":1720101040005,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mainks Sharma","userId":"04276220024164708980"}},"outputId":"5a617faa-4385-4bd0-bc3e-8fd4e85f36e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0 0.0 0.0 ... 1 1 101348.88]\n"," [0.0 0.0 1.0 ... 0 1 112542.58]\n"," [1.0 0.0 0.0 ... 1 0 113931.57]\n"," ...\n"," [1.0 0.0 0.0 ... 0 1 42085.58]\n"," [0.0 1.0 0.0 ... 1 0 92888.52]\n"," [1.0 0.0 0.0 ... 1 0 38190.78]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"vHol938cW8zd"},"source":["### Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train , X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2 , random_state = 0)"],"metadata":{"id":"IORYFovgAI7s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RE_FcHyfV3TQ"},"source":["### Feature Scaling"]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.fit_transform(X_test)\n","print(X_train)\n","print('\\n')\n","print(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jd5bpY2AgGe","executionInfo":{"status":"ok","timestamp":1720101040005,"user_tz":-330,"elapsed":3,"user":{"displayName":"Mainks Sharma","userId":"04276220024164708980"}},"outputId":"2db2ca6b-61ef-4b50-fae3-e7012be2df14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-1.01460667 -0.5698444   1.74309049 ...  0.64259497 -1.03227043\n","   1.10643166]\n"," [-1.01460667  1.75486502 -0.57369368 ...  0.64259497  0.9687384\n","  -0.74866447]\n"," [ 0.98560362 -0.5698444  -0.57369368 ...  0.64259497 -1.03227043\n","   1.48533467]\n"," ...\n"," [ 0.98560362 -0.5698444  -0.57369368 ...  0.64259497 -1.03227043\n","   1.41231994]\n"," [-1.01460667 -0.5698444   1.74309049 ...  0.64259497  0.9687384\n","   0.84432121]\n"," [-1.01460667  1.75486502 -0.57369368 ...  0.64259497 -1.03227043\n","   0.32472465]]\n","\n","\n","[[-0.95692675  1.62776996 -0.57427105 ...  0.66011376  0.97628121\n","   1.62185911]\n"," [ 1.04501206 -0.61433742 -0.57427105 ...  0.66011376 -1.02429504\n","   0.504204  ]\n"," [-0.95692675 -0.61433742  1.74133801 ...  0.66011376  0.97628121\n","  -0.41865644]\n"," ...\n"," [-0.95692675 -0.61433742  1.74133801 ...  0.66011376 -1.02429504\n","   0.72775202]\n"," [-0.95692675  1.62776996 -0.57427105 ...  0.66011376  0.97628121\n","  -1.54162886]\n"," [-0.95692675  1.62776996 -0.57427105 ...  0.66011376 -1.02429504\n","   1.62356528]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"-zfEzkRVXIwF"},"source":["## Part 2 - Building the ANN"]},{"cell_type":"markdown","metadata":{"id":"KvdeScabXtlB"},"source":["### Initializing the ANN"]},{"cell_type":"code","source":["#API - Application Programming Interface\n","#Building the sequence of layers of Neural networks from the i/p to the o/p layer & hidden layer in between\n","#Using the sequential function to create in sequence ,\n","#Computational graphs as non sequential  is boltzmann machine, neurons connected in any way not in successive layers. (not covered here)\n","#So to implement ANN Sequential neuron layers , Tensorflow2.0 library/Api to ðŸ‘‰ Keras Api ðŸ‘‰ model module ðŸ‘‰ sequential class/attribute is imported\n","#First keras and tensorflow were separate , now they integrated together in Tensorflow2.0 update\n","#Keras was separate library/API before , now keras is module within tensorflow2.0\n","#Sequential class is used to implement ANN\n","#Error : module 'keras.api._v2.keras.models' has no attribute 'sequential'\n","\n","ann = tf.keras.models.Sequential()     #In sequence - i/p - hidden layer - o/p layer  , classes always have first letter capital\n","\n","#no of i/p neurons in i/p layer are automatically detected by tensorflow & created acc to no of independent variables = i/p neurons\n","\n","#ann is variable as an object of this imported Sequential class\n","\n","#Now above we've created a neural network in sequential order , skeletal structure of ANN"],"metadata":{"id":"_OyxAEJ1V7GA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rP6urV6SX7kS"},"source":["### Adding the input layer and the first hidden layer"]},{"cell_type":"code","source":["#Add function will help add a layer\n","#Famous \"dense\" class in tensorflow and pytorch libraries is used to add fully connected layer into an ANN at any stage of ANN\n","#path to call this class is (tf library)-(keras)-(layers module) - (Dense class)\n","#As within layers we've no of neurons to be added within each layer\n","#Parameters within this class is Units- no of neurons - most asked ques in deep learning - how to determine the no of neurons in each layers\n","#It's done on experimentn basis - used six neurons majorly\n","#calling object of sequential class ann to add an i/p layer to it\n","\n","ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))     # classes always have first letter capital\n","                             #No of neurons\n","\n","#2nd parameter is Activation fxn to be assigned within neurons = Rectifier activation fxn, representd by 'ReLU'\n","#Activation fxn breaks the linearity b/w the i/p and hidden layer & execute the i/p data to provide the o/p\n","#In this way we've created the first layer of our Neural Network\n","\n","\n","#No activation function required for the regression as o/p is numerical,\n","#only for classification, sigmoid (2 categories) or softmax(3 categories) activation fn it is required as we Obtain categorical data of larger scope\n"],"metadata":{"id":"_0IY--5xXyX_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BELWAc_8YJze"},"source":["### Adding the second hidden layer"]},{"cell_type":"code","source":["#Adding 2nd layer is same as adding initial i/p layer\n","ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))   #Dense class creates the linkage b/w i/p Neurons and hidden layer neurons of ANN.\n","\n","#Add method can add layer in ANN at any stage of the imlementation\n"],"metadata":{"id":"YuYvtFeSezpe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OyNEe6RXYcU4"},"source":["### Adding the output layer"]},{"cell_type":"code","source":["#Adding o/p layer will take diff parameters else same\n","ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n","\n","#Using the rectifier activation function in hidden layer & Sigmoid activation function in the o/p layer - probabilistic way to get binary\n","#outcomes , whether user will leave or not in probabilistic value.\n","\n","#when o/p is binary , activation function = sigmoid\n","#when o/p is non-binary , activation function = softmax (-âˆž to +âˆž on x axis, yaxis = 0 to 1 , threshold at 0.5 )\n","\n","#Here the neural network is implemented - (Artificial neural brain)"],"metadata":{"id":"4xv1UEN8fsIW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JT4u2S1_Y4WG"},"source":["## Part 3 - Training the ANN"]},{"cell_type":"markdown","metadata":{"id":"8GWlJChhY_ZI"},"source":["### Compiling the ANN"]},{"cell_type":"code","source":["#After ANN is designed , it's to be trained now\n","#Compliling the ANN with optimizer and loss function and a metric = accuracy as we're dealing with classification here.\n","\n","# Optimizer , loss function & metrics = accuracy are parameters of 'compile' function in tensorflow\n","\n","ann.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])  #metrics as accuracy is used\n","\n","#Optimizer is the tool by which your'e going to perform the stochastic gradient descent\n","#Optimizer is connected to take care of loss during back-propagtion for weight updation\n","\n","#Optimizer = which method to evaluate with = stochastic gradient descent = 'adam' , weight updation is done via stochastic method\n","#loss function used in binary outcome is used = binary_crossentropy\n","#The way ANN Will evaluate the Cost function is given as loss ='' as parameter\n","#loss function used in Non-binary outcome is used = categorical_crossentropy\n","#mean_squared_error is loss fxn while implementing ANN in Regression , binary_crossentropy for classification"],"metadata":{"id":"HnLreHHVuSet"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0QR_G5u7ZLSM"},"source":["### Training the ANN on the Training set"]},{"cell_type":"code","source":["#Now training of ANN by feeding the training data is to be done:\n","#fit function is used to train the ANN , it will take the parameter from dataset and train ANN on it.\n","\n","ann.fit(X_train , y_train, batch_size = 32 , epochs = 100)\n","\n","#For Batch learning, batch_size is used as we're going to have the batch weight updation , default is 32 , you can tune the hyperparameter too.\n","#Meaning out of 1000 rows , 32 in each batch are splitted are fed.\n","#epochs is the cycles the training data is to fed to th ANN network to improve accuracy ,1 cycle = 1 epoch\n","#For each epochs , error is minimised and accuracy is increased.\n","\n","#We've made the skeletal ann structure ,added i/p , hidden and o/p layer , then provided method/activË†n fxn for hidden neurons to work ,\n","# for back proagation , which method/optimizer, loss fxn to use and at last fitting the dataset and trained our ANN On given data.\n","#(Working) - For these value of independent variable , we have these o/p and would be run 1000 times & model will crate the relation b/w the variables & further predict the value for test data.\n","#Column being fixed at neurons , each row data one by one is feed into neuron till o/p & ANN builds a correlation.\n","#In this way complete ANN is implemented & further is to be predicted"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PCNE9OMOzJAz","executionInfo":{"status":"ok","timestamp":1720101125275,"user_tz":-330,"elapsed":84530,"user":{"displayName":"Mainks Sharma","userId":"04276220024164708980"}},"outputId":"ea42655e-5902-47b6-d001-12e14844d294"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","250/250 [==============================] - 4s 6ms/step - loss: 0.5444 - accuracy: 0.7588\n","Epoch 2/100\n","250/250 [==============================] - 2s 7ms/step - loss: 0.4606 - accuracy: 0.8058\n","Epoch 3/100\n","250/250 [==============================] - 3s 10ms/step - loss: 0.4375 - accuracy: 0.8119\n","Epoch 4/100\n","250/250 [==============================] - 2s 9ms/step - loss: 0.4255 - accuracy: 0.8196\n","Epoch 5/100\n","250/250 [==============================] - 2s 7ms/step - loss: 0.4173 - accuracy: 0.8226\n","Epoch 6/100\n","250/250 [==============================] - 1s 6ms/step - loss: 0.4108 - accuracy: 0.8248\n","Epoch 7/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.4068 - accuracy: 0.8257\n","Epoch 8/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.4024 - accuracy: 0.8259\n","Epoch 9/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3986 - accuracy: 0.8265\n","Epoch 10/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3937 - accuracy: 0.8304\n","Epoch 11/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3877 - accuracy: 0.8330\n","Epoch 12/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3810 - accuracy: 0.8394\n","Epoch 13/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3743 - accuracy: 0.8426\n","Epoch 14/100\n","250/250 [==============================] - 2s 7ms/step - loss: 0.3685 - accuracy: 0.8451\n","Epoch 15/100\n","250/250 [==============================] - 1s 5ms/step - loss: 0.3634 - accuracy: 0.8508\n","Epoch 16/100\n","250/250 [==============================] - 2s 6ms/step - loss: 0.3601 - accuracy: 0.8516\n","Epoch 17/100\n","250/250 [==============================] - 1s 5ms/step - loss: 0.3567 - accuracy: 0.8529\n","Epoch 18/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3542 - accuracy: 0.8546\n","Epoch 19/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8550\n","Epoch 20/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3515 - accuracy: 0.8584\n","Epoch 21/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8577\n","Epoch 22/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3491 - accuracy: 0.8579\n","Epoch 23/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.8581\n","Epoch 24/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8599\n","Epoch 25/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3464 - accuracy: 0.8586\n","Epoch 26/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3450 - accuracy: 0.8606\n","Epoch 27/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3450 - accuracy: 0.8585\n","Epoch 28/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3445 - accuracy: 0.8605\n","Epoch 29/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3440 - accuracy: 0.8608\n","Epoch 30/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3435 - accuracy: 0.8616\n","Epoch 31/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3426 - accuracy: 0.8622\n","Epoch 32/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3421 - accuracy: 0.8615\n","Epoch 33/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3417 - accuracy: 0.8625\n","Epoch 34/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3418 - accuracy: 0.8621\n","Epoch 35/100\n","250/250 [==============================] - 1s 5ms/step - loss: 0.3413 - accuracy: 0.8618\n","Epoch 36/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3410 - accuracy: 0.8629\n","Epoch 37/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3408 - accuracy: 0.8616\n","Epoch 38/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3408 - accuracy: 0.8615\n","Epoch 39/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3402 - accuracy: 0.8622\n","Epoch 40/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8629\n","Epoch 41/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.8621\n","Epoch 42/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3387 - accuracy: 0.8627\n","Epoch 43/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3390 - accuracy: 0.8626\n","Epoch 44/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8644\n","Epoch 45/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3382 - accuracy: 0.8620\n","Epoch 46/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3374 - accuracy: 0.8641\n","Epoch 47/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3379 - accuracy: 0.8620\n","Epoch 48/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3372 - accuracy: 0.8633\n","Epoch 49/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3371 - accuracy: 0.8618\n","Epoch 50/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8620\n","Epoch 51/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3370 - accuracy: 0.8624\n","Epoch 52/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.8609\n","Epoch 53/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3360 - accuracy: 0.8620\n","Epoch 54/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3365 - accuracy: 0.8614\n","Epoch 55/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3356 - accuracy: 0.8621\n","Epoch 56/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8627\n","Epoch 57/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.8636\n","Epoch 58/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.8631\n","Epoch 59/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8634\n","Epoch 60/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.8639\n","Epoch 61/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8639\n","Epoch 62/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.8640\n","Epoch 63/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8635\n","Epoch 64/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3344 - accuracy: 0.8639\n","Epoch 65/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.8640\n","Epoch 66/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3344 - accuracy: 0.8619\n","Epoch 67/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3342 - accuracy: 0.8620\n","Epoch 68/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3343 - accuracy: 0.8650\n","Epoch 69/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.8619\n","Epoch 70/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3337 - accuracy: 0.8635\n","Epoch 71/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8655\n","Epoch 72/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3344 - accuracy: 0.8631\n","Epoch 73/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3342 - accuracy: 0.8640\n","Epoch 74/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8615\n","Epoch 75/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8634\n","Epoch 76/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3339 - accuracy: 0.8635\n","Epoch 77/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3340 - accuracy: 0.8630\n","Epoch 78/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8622\n","Epoch 79/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8621\n","Epoch 80/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.8633\n","Epoch 81/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8629\n","Epoch 82/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8629\n","Epoch 83/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.8644\n","Epoch 84/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.8631\n","Epoch 85/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8635\n","Epoch 86/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8639\n","Epoch 87/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8629\n","Epoch 88/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8629\n","Epoch 89/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8645\n","Epoch 90/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8633\n","Epoch 91/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3332 - accuracy: 0.8645\n","Epoch 92/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.8652\n","Epoch 93/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3331 - accuracy: 0.8631\n","Epoch 94/100\n","250/250 [==============================] - 1s 5ms/step - loss: 0.3330 - accuracy: 0.8636\n","Epoch 95/100\n","250/250 [==============================] - 2s 7ms/step - loss: 0.3327 - accuracy: 0.8648\n","Epoch 96/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.8639\n","Epoch 97/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.8639\n","Epoch 98/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8633\n","Epoch 99/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8639\n","Epoch 100/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3335 - accuracy: 0.8634\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7af0846f1570>"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"tJj5k2MxZga3"},"source":["## Part 4 - Making the predictions and evaluating the model"]},{"cell_type":"markdown","metadata":{"id":"84QFoqGYeXHL"},"source":["### Predicting the result of a single observation\n","\n","\n","\n","Use our ANN model to predict if the customer with the following informations will leave the bank:\n","\n","Geography: France\n","\n","Credit Score: 600\n","\n","Gender: Male\n","\n","Age: 40 years old\n","\n","Tenure: 3 years\n","\n","Balance: \\$ 60000\n","\n","Number of Products: 2\n","\n","Does this customer have a credit card? Yes\n","\n","Is this customer an Active Member: Yes\n","\n","Estimated Salary: \\$ 50000\n","\n","So, should we say goodbye to that customer?"]},{"cell_type":"markdown","metadata":{"id":"ZhU1LTgPg-kH"},"source":["**Solution**"]},{"cell_type":"code","metadata":{"id":"2d8IoCCkeWGL","outputId":"b986bb4e-63d8-4d85-d5d5-0e8747dacd86","executionInfo":{"status":"ok","timestamp":1720101126012,"user_tz":-330,"elapsed":744,"user":{"displayName":"Mainks Sharma","userId":"04276220024164708980"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["#1st - As we've done the encoding on our categorical data , we need to check , France = 1,0,0 & male = 1\n","#2nd - Also we've trained our data on feature scaled values, we need to provide scaled values only to the model for further predicting on test data too.\n","\n","print(ann.predict(sc.transform([[1, 0, 1, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]))) #yields probability = 0.04 prob to leave bank\n","print(ann.predict(sc.transform([[1, 0, 1, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) >0.5) #yields categorical value\n","#here we set the threshold to 0.5 , if above it true will be printed & below false will be printed\n","\n","\n","# we can also do this\n","if ann.predict(sc.transform([[1, 0, 1, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) >0.5:\n","  print(\"Customer will leave the bank\")\n","else:\n","  print(\"Don't worry customer won't leave the bank\")\n","\n","#we implemented all 3 ways here to print the o/p in different ways - prob - categorical - if else.\n","\n","#So transform the values first to same scale feature scaling is done , then predict those values using ANN\n","#Also we've used the Sigmoid fxn on o/p layer gives probability , we need to change the probability to categorical value as :"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 158ms/step\n","[[0.06259743]]\n","1/1 [==============================] - 0s 43ms/step\n","[[False]]\n","1/1 [==============================] - 0s 32ms/step\n","Don't worry customer won't leave the bank\n"]}]},{"cell_type":"markdown","metadata":{"id":"wGjx94g2n7OV"},"source":["Therefore, our ANN model predicts that this customer stays in the bank!\n","\n","**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n","\n","**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."]},{"cell_type":"markdown","metadata":{"id":"u7yx47jPZt11"},"source":["### Predicting the Test set results"]},{"cell_type":"code","source":["y_pred = ann.predict(X_test) > 0.5   #again o/p = prob , convert to categorical by adding threshold on sigmoid obtained values =0.5\n","print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))\n","\n","#numpy as np is used to deal with numerical calcualtion , matrix creation and altering modifying values in implementation.\n","#concatenate - create a matrix with given i/p parameters\n","#In this way , we printed both predicted and actual values in a matrix side by side\n","\n","#we've got actual values to model predicted value matrix below\n","# 1 = leaves 0 - stays in bank"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QqYhi3xl-1Qi","executionInfo":{"status":"ok","timestamp":1720101126012,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mainks Sharma","userId":"04276220024164708980"}},"outputId":"68740247-5617-47ce-919a-21d0f5e3e0fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["63/63 [==============================] - 0s 3ms/step\n","[[0 0]\n"," [0 1]\n"," [0 0]\n"," ...\n"," [0 0]\n"," [0 0]\n"," [0 0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"o0oyfLWoaEGw"},"source":["### Making the Confusion Matrix"]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, accuracy_score\n","cm = confusion_matrix(y_pred, y_test)\n","print(cm)\n","accuracy_score(y_pred, y_test)\n","\n","#out of 100 - 86 customers predicted correctly"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F3FjAwAh_8dU","executionInfo":{"status":"ok","timestamp":1720101126012,"user_tz":-330,"elapsed":3,"user":{"displayName":"Mainks Sharma","userId":"04276220024164708980"}},"outputId":"fbe8ffca-b8d9-468e-a702-272f3298fb2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1523  212]\n"," [  72  193]]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.858"]},"metadata":{},"execution_count":15}]}]}