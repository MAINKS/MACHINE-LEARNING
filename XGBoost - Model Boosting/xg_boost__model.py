# -*- coding: utf-8 -*-
"""XG_Boost_.Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v0BbR4Hl7qhGxs9-dtLndOMezwvqt0Cp

# XGBoost
"""

#As we've implemented the various regression models as logistic, KNN, SVC, KernelSVC, Naive Bayes, Decision tree, Random forest Classification
#on Data.csv to predict the Tumour as in two categories, ml model predicts tumour as benign or malignant
#In xg boost we're gonna implement the same prediction using XGBoost model to habe better accuracy
#Then apply K fold cross validation on XGBoost model, so as to more increase in accuracy.

#XGBoost is another Predictive model used for classification and regression just like we'd Knn or Naive bayes etc.

"""## Importing the libraries"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""## Importing the dataset"""

dataset = pd.read_csv('Data.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y=le.fit_transform(y)

"""## Splitting the dataset into the Training set and Test set"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

"""## Training XGBoost on the Training set"""

#Just like Scikitlearn have various models and deals with dataset & implementation for various models,
#For implementation of XGBoost Model, we've xgboost library, with XGBClassifier for classification & XGBRegressor for regression model

from xgboost import XGBClassifier
classifier = XGBClassifier()
classifier.fit(X_train, y_train)

"""## Making the Confusion Matrix"""

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

#We've got the amazing accuracy of 97.8 = 98% which is greater than accuracy of all other Classification models on such.

"""## Applying k-Fold Cross Validation"""

#Then applying Kfold on XGBOOST Classifier to train model on 10 diff sets and predicting accuracies & model with highest accuracy will be used.
#On 10 different test sets obtained accuracy with low deviation/variance

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv =10)
print("Accuracy: {:.2f} %".format(accuracies.mean()*100))
print("Standard Deviation: {:.2f} %".format(accuracies.std()*100))