# -*- coding: utf-8 -*-
"""Polynomial0_regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11bvsBvimGigMX6PWa14Ciu2eKNoP7OoR

# Polynomial linear Regression

Polynomial regression consist of the variables with power

Used to overcome the drawbacks of Simple linear regression as it somewhat doesn't fit the datapoints much accurately.

PR = b0+b1x1+b2x2ˆ2+b3x3ˆ3+---bnxnˆn

These squared cubes value provide that parabolic effect to the curve in place of linear curve in linear regression.

Called polynomial linear regression beacause linearity is achieved by the linear coefficients b1 b2 & polynomial regression is still called Polynomial linear Regression - an example of multiple linear regression.

Position level vs salaries

The .fit function in a machine learning model establishes the relationship between the feature matrix X (independent variables) and the target vector y (dependent variable) by learning the optimal parameters that map X to y

## Importing the libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""## Importing the dataset"""

dataset = pd.read_csv('Position_Salaries.csv')
X= dataset.iloc[:,1:-1].values
y = dataset.iloc[:,-1].values

"""## Training the Linear Regression model on the whole dataset"""

from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()           #linear regressor
lin_reg.fit(X,y)

"""## Training the Polynomial Regression model on the whole dataset"""

from sklearn.preprocessing import PolynomialFeatures #We're gonna create the Matrix feature X containing polynomial values
poly_reg = PolynomialFeatures(degree=4) #degree indicates max power of polynomial function (xˆn)
X_poly = poly_reg.fit_transform(X)      #Convert Matrix X to Matirx X_poly having polynomial features (x1,x2ˆ2,x3ˆ3 and all).  X_poly conatins position levels & square of postion levels  , y = salary
lin_reg2 = LinearRegression()           #We've X matrix converted to polynomial fxn in X_poly , now to combine these features with coefficient to form a Polynomial regreesion fxn y=b0+b1x1+b2x2ˆ2+b3x3ˆ3+---bnxnˆn we'll use linear regrssion template.
lin_reg2.fit(X_poly,y)                  #X_poly and y fitted

"""## Visualising the Linear Regression results"""

plt.scatter(X,y , color='red')       #Scatter creates 'points' indicating y for value of X
plt.plot(X,lin_reg.predict(X), color = 'orange')     #Plot draws curve representing y for value of X
plt.title('Real or Bluff (Linear regression)')
plt.xlabel('Position level of employee')
plt.ylabel('Salary corresponding to that position level')
plt.show()   #For graphically representing the plot generated above

#Here linear regression is not highly accurate as real vs predicted values differs a lot
#(Ex - for positon level 6 real salary is 8k & predicted is way higher above 20k that leads to overpaying employee-
#not best adapted- not the best negotiation - real value is far from prediction)

"""## Visualising the Polynomial Regression results"""

plt.scatter(X,y , color='purple')
plt.plot(X,lin_reg2.predict(poly_reg.fit_transform(X)) , color= 'violet')
plt.title('Real or bluff(Polynomial regression)')
plt.xlabel('Position level')
plt.ylabel('Salary')
plt.show()

#Way more adaptive curve that's much more closer to real results are obtained
#As degree increases curve accuracy also increases linearly

"""## Visualising the Polynomial Regression results (for higher resolution and smoother curve)
More precised & accurate curve
"""

X_grid = np.arange(min(X), max(X), 0.1)     #More no of datapoints as gap is 0.1, with arranged in ascending order - density increased - (1 ,1.1 ,1.2---9.9,10)
X_grid = X_grid.reshape((len(X_grid), 1))
plt.scatter(X, y, color = 'red')
plt.plot(X_grid, lin_reg2.predict(poly_reg.fit_transform(X_grid)), color = 'blue')
plt.title('Truth or Bluff (Polynomial Regression)')
plt.xlabel('Position level')
plt.ylabel('Salary')
plt.show()

"""## Predicting a new result with Linear Regression"""

#Input for predicting new value is to be given as 2D array parameter. single bracket is for list & double for an array(rows & columns)

lin_reg.predict([[6.5]])  #Suppose we want to predict salary for position level = 6.5

#Predicted salary in linear regression = 330k and real salary is 150k , not feasible as company gonna pay way too much than required/Prev company

"""## Predicting a new result with Polynomial Regression"""

lin_reg2.predict(poly_reg.fit_transform([[6.5]]))

#y_poly=b0+b1x1+b2(6.5)ˆ2+b3(6.5)ˆ3+---
#Predicted accurately as compared to linear regression