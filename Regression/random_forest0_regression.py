# -*- coding: utf-8 -*-
"""Random_forest0_regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/139dNsSJ2ohWYkmvq6K1F37yE6voO_tAD

# Random Forest Regression

Group of multiple decision tree regression.

Similar to random forest on classification trees.

Random forest is a version of **Ensemble Learning** .

**Ensemble learning is when you takes multiple algorithms or the same algorithm multiple times & you put them together to make something more powerful than original.**

Building Decision tree not for whole dataset but for subset having K data points.
-------------------------------------
Implementation : Step 1 : Pick at random K data points from the Training set.

STEP 2: Build the Decision Tree associated to these K data points.

STEP 3: Choose the (Ntree) number of trees you want to build and repeat STEPS 1 & 2

STEP 4: For a new data point, make each one of your Ntree trees predict the value of Y to for the data point in question, and assign the new data point the average across all of the predicted Y values.
--------------------------------------
Majorly 500 decision trees predicts the value of new datapoints & average of those gives final prediction.

Instead of one tree using forest of trees in random forest regression for new datapoint prediction & it increases accuracy as average of many leads to minimising error in one tree due to preserveance as changes in dataset could impact one tree but won't affect forest of trees.

Ex - Guessing no of marbles in a box , noting the random guess of 100 people and calculating average and median of them excluding outliers and exception values - Only way to guess using the Data science statistical strategy.


Random forest Regression is also highly adapted to high dimensional data.

## Importing the libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""## Importing the dataset"""

dataset = pd.read_csv('Position_Salaries.csv')
X = dataset.iloc[:,1:-1].values
y = dataset.iloc[:,-1].values

"""## Training the Random Forest Regression model on the whole dataset"""

# Now look : RandomForestRegressor class from 'ensemble' module of scikitlearn library is used
# n_estimators represents = number of Decision trees in the forest

from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(n_estimators = 1000 , random_state=0)
regressor.fit(X,y)

"""## Predicting a new result"""

regressor.predict([[6.5]])   # more accurate prediction than single decision tree

"""## Visualising the Random Forest Regression results (higher resolution)"""

#No of stair steps increased to double in RandomTreeRegressor as in decision tree one stair for two datapoint
#range was there but in RandomForest each datapoint posses different stair for prediction.

X_grid = np.arange(min(X),max(X),0.01)
X_grid = X_grid.reshape((len(X_grid),1))
plt.scatter(X,y,color='pink')
plt.plot(X_grid,regressor.predict(X_grid),color='green')
plt.title('Random forest Regression')
plt.xlabel('Position level')
plt.ylabel('Truth or Bluff ( Salary )')
plt.show()